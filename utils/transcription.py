# -*- coding: utf-8 -*-
"""
–¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è –∞—É–¥–∏–æ Local Transcriber
Copyright (C) 2025 Local Transcriber Project

This program is free software: you can redistribute it and/or modify
it under the terms of the GNU General Public License as published by
the Free Software Foundation, either version 3 of the License, or
(at your option) any later version.
"""

import os
from pathlib import Path
from typing import List, Optional, Dict, Any
from datetime import datetime
import tempfile

from config.logging_config import get_logger, log_function_call, log_processing_step, log_progress
from app.models import ProcessingJob, ProcessingStatus, SpeakerSegment
from utils.file_manager import FileManager
from utils.audio_processor import AudioProcessor
from utils.speaker_diarization import SpeakerDiarizer

logger = get_logger('transcription')

class TranscriptionProcessor:
    """–û—Å–Ω–æ–≤–Ω–æ–π –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏, –æ–±—ä–µ–¥–∏–Ω—è—é—â–∏–π –≤—Å–µ —ç—Ç–∞–ø—ã."""
    
    def __init__(self, upload_folder: str, results_folder: str, 
                 whisper_model: str = "medium", hf_token: Optional[str] = None):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏.
        
        Args:
            upload_folder: –ü–∞–ø–∫–∞ –¥–ª—è –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
            results_folder: –ü–∞–ø–∫–∞ –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            whisper_model: –ú–æ–¥–µ–ª—å Whisper –¥–ª—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏
            hf_token: –¢–æ–∫–µ–Ω Hugging Face
        """
        self.upload_folder = Path(upload_folder)
        self.results_folder = Path(results_folder)
        self.whisper_model_name = whisper_model
        self.hf_token = hf_token
        self.whisper_model = None
        
        # –°–æ–∑–¥–∞–Ω–∏–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π
        self.upload_folder.mkdir(parents=True, exist_ok=True)
        self.results_folder.mkdir(parents=True, exist_ok=True)
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
        self.file_manager = FileManager(str(upload_folder))
        self.audio_processor = AudioProcessor(str(upload_folder))
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –¥–∏–∞—Ä–∏–∑–∞—Ç–æ—Ä–∞ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
        self.speaker_diarizer = None
        logger.info("–ü–æ–ø—ã—Ç–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ pyannote –¥–∏–∞—Ä–∏–∑–∞—Ç–æ—Ä–∞...")
        try:
            # –ü—Ä–æ–±—É–µ–º —Ç–æ–ª—å–∫–æ pyannote –¥–∏–∞—Ä–∏–∑–∞—Ü–∏—é
            from .speaker_diarization import SpeakerDiarizer
            logger.info("–ú–æ–¥—É–ª—å speaker_diarization –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω —É—Å–ø–µ—à–Ω–æ")
            self.speaker_diarizer = SpeakerDiarizer(hf_token=hf_token)
            logger.info("‚úÖ Pyannote –¥–∏–∞—Ä–∏–∑–∞—Ç–æ—Ä —Å–ø–∏–∫–µ—Ä–æ–≤ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω —É—Å–ø–µ—à–Ω–æ!")
        except Exception as e:
            logger.error(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å pyannote –¥–∏–∞—Ä–∏–∑–∞—Ç–æ—Ä: {str(e)}")
            logger.error(f"–¢–∏–ø –æ—à–∏–±–∫–∏: {type(e).__name__}")
            import traceback
            logger.error(f"–ü–æ–ª–Ω–∞—è –æ—à–∏–±–∫–∞:\n{traceback.format_exc()}")
            logger.info("–ü—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –±—É–¥–µ—Ç —Ä–∞–±–æ—Ç–∞—Ç—å –±–µ–∑ –¥–∏–∞—Ä–∏–∑–∞—Ü–∏–∏ —Å–ø–∏–∫–µ—Ä–æ–≤ - —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è —Ü–µ–ª—ã—Ö —Ñ–∞–π–ª–æ–≤")
        
        # –§–∏–Ω–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ—Å—Ç–æ—è–Ω–∏—è –¥–∏–∞—Ä–∏–∑–∞—Ç–æ—Ä–∞
        if self.speaker_diarizer:
            if hasattr(self.speaker_diarizer, 'pipeline') and self.speaker_diarizer.pipeline is not None:
                logger.info("üéâ –î–∏–∞—Ä–∏–∑–∞—Ü–∏—è –ø–æ–ª–Ω–æ—Å—Ç—å—é –≥–æ—Ç–æ–≤–∞ –∫ —Ä–∞–±–æ—Ç–µ!")
            else:
                logger.warning("‚ö†Ô∏è –î–∏–∞—Ä–∏–∑–∞—Ç–æ—Ä —Å–æ–∑–¥–∞–Ω, –Ω–æ pipeline –Ω–µ –≥–æ—Ç–æ–≤ - –±—É–¥–µ—Ç –æ—Ç–∫–ª—é—á–µ–Ω –ø—Ä–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–∏")
        else:
            logger.info("‚ÑπÔ∏è –î–∏–∞—Ä–∏–∑–∞—Ü–∏—è –æ—Ç–∫–ª—é—á–µ–Ω–∞ - –±—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è –ø–æ–ª–Ω–∞—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è —Ñ–∞–π–ª–æ–≤")
        
        logger.info(f"TranscriptionProcessor –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω: model={whisper_model}")
        self._initialize_whisper()
    
    def _initialize_whisper(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ Whisper."""
        try:
            log_processing_step("–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ Whisper", self.whisper_model_name)
            
            import whisper
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å Whisper
            self.whisper_model = whisper.load_model(self.whisper_model_name)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å GPU
            try:
                import torch
                if torch.cuda.is_available():
                    logger.info("Whisper –±—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å GPU")
                else:
                    logger.info("Whisper –±—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å CPU")
            except ImportError:
                logger.info("PyTorch –Ω–µ –Ω–∞–π–¥–µ–Ω, Whisper –±—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å CPU")
            
            logger.info("–ú–æ–¥–µ–ª—å Whisper —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
        
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏ Whisper: {str(e)}")
            raise RuntimeError(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª—å Whisper: {str(e)}")
    
    @log_function_call
    def transcribe_audio_segment_with_context(self, audio_path: str, start_time: float, 
                                            end_time: float, context_before: float = 1.0,
                                            context_after: float = 1.0) -> Optional[str]:
        """
        –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä–æ–≤–∞—Ç—å —Å–µ–≥–º–µ–Ω—Ç –∞—É–¥–∏–æ —Å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º.
        
        Args:
            audio_path: –ü—É—Ç—å –∫ –∞—É–¥–∏–æ —Ñ–∞–π–ª—É
            start_time: –í—Ä–µ–º—è –Ω–∞—á–∞–ª–∞ —Å–µ–≥–º–µ–Ω—Ç–∞ –≤ —Å–µ–∫—É–Ω–¥–∞—Ö
            end_time: –í—Ä–µ–º—è –∫–æ–Ω—Ü–∞ —Å–µ–≥–º–µ–Ω—Ç–∞ –≤ —Å–µ–∫—É–Ω–¥–∞—Ö
            context_before: –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–æ —Å–µ–≥–º–µ–Ω—Ç–∞ –≤ —Å–µ–∫—É–Ω–¥–∞—Ö
            context_after: –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –ø–æ—Å–ª–µ —Å–µ–≥–º–µ–Ω—Ç–∞ –≤ —Å–µ–∫—É–Ω–¥–∞—Ö
            
        Returns:
            str: –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –æ—Å–Ω–æ–≤–Ω–æ–≥–æ —Å–µ–≥–º–µ–Ω—Ç–∞ –∏–ª–∏ None –ø—Ä–∏ –æ—à–∏–±–∫–µ
        """
        try:
            if not self.whisper_model:
                raise RuntimeError("–ú–æ–¥–µ–ª—å Whisper –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞")
            
            # –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–µ –≥—Ä–∞–Ω–∏—Ü—ã —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º
            extended_start = max(0.0, start_time - context_before)
            extended_end = end_time + context_after
            
            # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª –¥–ª—è —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–≥–æ —Å–µ–≥–º–µ–Ω—Ç–∞
            temp_file = self.file_manager.create_temp_file(suffix=".wav")
            
            try:
                # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π —Å–µ–≥–º–µ–Ω—Ç
                if not self.audio_processor.extract_audio_segment(
                    audio_path, temp_file, extended_start, extended_end - extended_start):
                    logger.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π —Å–µ–≥–º–µ–Ω—Ç {extended_start}-{extended_end}")
                    return None
                
                # –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä—É–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π —Å–µ–≥–º–µ–Ω—Ç (–æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–æ –ø—Ä–æ—Ç–∏–≤ –≥–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏–π)
                result = self.whisper_model.transcribe(
                    temp_file,
                    language='ru',
                    task='transcribe',
                    # –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω–æ–π —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏
                    temperature=0.0,
                    beam_size=1,      # –ü—Ä–æ—Å—Ç–æ–π –ø–æ–∏—Å–∫ –±–µ–∑ –ø–µ—Ä–µ–±–æ—Ä–∫–∏
                    best_of=1,        # –û–¥–∏–Ω –≤–∞—Ä–∏–∞–Ω—Ç
                    # –ù–ï –∏—Å–ø–æ–ª—å–∑—É–µ–º initial_prompt - –∏—Å—Ç–æ—á–Ω–∏–∫ –≥–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏–π!
                    condition_on_previous_text=True,  # –ö–æ–Ω—Ç–µ–∫—Å—Ç –ø–æ–º–æ–≥–∞–µ—Ç
                    fp16=False,
                    compression_ratio_threshold=2.4,
                    logprob_threshold=-1.0,
                    no_speech_threshold=0.6,
                    # –ü–æ–¥–∞–≤–ª—è–µ–º –ø—Ä–æ–±–ª–µ–º–Ω—ã–µ —Ç–æ–∫–µ–Ω—ã
                    suppress_tokens=[50256, 50257, 50258, 50259, 50260, 50261, 50262, 50263, 50264, 50265],
                    # –î–æ–±–∞–≤–ª—è–µ–º word-level timestamps –¥–ª—è —Ç–æ—á–Ω–æ–≥–æ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è
                    word_timestamps=True
                )
                
                # –ü–æ–ª—É—á–∞–µ–º –ø–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç —Å –≤—Ä–µ–º–µ–Ω–Ω—ã–º–∏ –º–µ—Ç–∫–∞–º–∏
                full_text = result.get('text', '').strip()
                segments_with_words = result.get('segments', [])
                
                if not full_text or not segments_with_words:
                    logger.debug(f"–ü—É—Å—Ç–∞—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è –¥–ª—è —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–≥–æ —Å–µ–≥–º–µ–Ω—Ç–∞ {extended_start:.2f}-{extended_end:.2f}s")
                    return None
                
                # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç, —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–π –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–º—É —Å–µ–≥–º–µ–Ω—Ç—É
                target_text = self._extract_text_by_time(
                    segments_with_words, 
                    start_time - extended_start,  # –û—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ–µ –≤—Ä–µ–º—è –Ω–∞—á–∞–ª–∞
                    end_time - extended_start     # –û—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ–µ –≤—Ä–µ–º—è –∫–æ–Ω—Ü–∞
                )
                
                if target_text:
                    # –§–∏–ª—å—Ç—Ä—É–µ–º –≥–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏–∏
                    target_text = self._filter_hallucinations(target_text)
                    logger.debug(f"–ö–æ–Ω—Ç–µ–∫—Å—Ç–Ω–∞—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è —Å–µ–≥–º–µ–Ω—Ç–∞ {start_time:.2f}-{end_time:.2f}s: '{target_text[:50]}...'")
                    return target_text
                else:
                    # Fallback –∫ –æ–±—ã—á–Ω–æ–π —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏ –µ—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å –ø–æ –≤—Ä–µ–º–µ–Ω–∏
                    logger.debug(f"Fallback –∫ –ø–æ–ª–Ω–æ–º—É —Ç–µ–∫—Å—Ç—É –¥–ª—è —Å–µ–≥–º–µ–Ω—Ç–∞ {start_time:.2f}-{end_time:.2f}s")
                    full_text = self._filter_hallucinations(full_text)
                    return full_text
                
            finally:
                # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
                self.file_manager.delete_file(temp_file)
        
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω–æ–π —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏ —Å–µ–≥–º–µ–Ω—Ç–∞ {start_time}-{end_time}: {str(e)}")
            # Fallback –∫ –æ–±—ã—á–Ω–æ–π —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏
            return self.transcribe_audio_segment(audio_path, start_time, end_time)

    def _extract_text_by_time(self, segments_with_words: List[Dict], 
                             target_start: float, target_end: float) -> Optional[str]:
        """
        –ò–∑–≤–ª–µ—á—å —Ç–µ–∫—Å—Ç –∏–∑ —Å–µ–≥–º–µ–Ω—Ç–æ–≤ –ø–æ –≤—Ä–µ–º–µ–Ω–Ω—ã–º –≥—Ä–∞–Ω–∏—Ü–∞–º.
        
        Args:
            segments_with_words: –°–µ–≥–º–µ–Ω—Ç—ã —Å word-level timestamps
            target_start: –ù–∞—á–∞–ª—å–Ω–æ–µ –≤—Ä–µ–º—è (–æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ–µ)
            target_end: –ö–æ–Ω–µ—á–Ω–æ–µ –≤—Ä–µ–º—è (–æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ–µ)
            
        Returns:
            str: –ò–∑–≤–ª–µ—á–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –∏–ª–∏ None
        """
        try:
            extracted_words = []
            
            for segment in segments_with_words:
                words = segment.get('words', [])
                for word_info in words:
                    word_start = word_info.get('start', 0.0)
                    word_end = word_info.get('end', 0.0)
                    word = word_info.get('word', '').strip()
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏–µ —Å —Ü–µ–ª–µ–≤—ã–º –∏–Ω—Ç–µ—Ä–≤–∞–ª–æ–º
                    if (word_start < target_end and word_end > target_start and word):
                        extracted_words.append(word)
            
            if extracted_words:
                result = ' '.join(extracted_words).strip()
                return result if result else None
            
            return None
        
        except Exception as e:
            logger.debug(f"–û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ –ø–æ –≤—Ä–µ–º–µ–Ω–∏: {str(e)}")
            return None

    def _filter_hallucinations(self, text: str) -> str:
        """
        –§–∏–ª—å—Ç—Ä–æ–≤–∞—Ç—å –≥–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏–∏ –∏ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç—ã –≤ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä–æ–≤–∞–Ω–Ω–æ–º —Ç–µ–∫—Å—Ç–µ.
        
        Args:
            text: –ò—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç
            
        Returns:
            str: –û—á–∏—â–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
        """
        if not text:
            return text
        
                # –°–ø–∏—Å–æ–∫ —Ñ—Ä–∞–∑-–≥–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏–π, –∫–æ—Ç–æ—Ä—ã–µ –Ω—É–∂–Ω–æ —É–¥–∞–ª–∏—Ç—å
        hallucination_patterns = [
            r'—Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è\s+(—Ñ—Ä–∞–≥–º–µ–Ω—Ç–∞\s+)?—Ç–µ–ª–µ—Ñ–æ–Ω–Ω–æ–≥–æ\s+—Ä–∞–∑–≥–æ–≤–æ—Ä–∞.*',
            r'—Ñ—Ä–∞–≥–º–µ–Ω—Ç(–∞|—ã)?\s+(—Ç–µ–ª–µ—Ñ–æ–Ω–Ω–æ–≥–æ\s+)?—Ä–∞–∑–≥–æ–≤–æ—Ä–∞.*',
            r'–Ω–∞\s+—Ä—É—Å—Å–∫–æ–º\s+—è–∑—ã–∫–µ.*–º–µ–∂–¥—É.*—Å–æ–±–µ—Å–µ–¥–Ω–∏–∫–∞–º–∏?',
            r'—Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è.*–Ω–∞\s+—Ä—É—Å—Å–∫–æ–º\s+—è–∑—ã–∫–µ',
            r'–º–µ–∂–¥—É\s+–¥–≤—É–º—è\s+—Å–æ–±–µ—Å–µ–¥–Ω–∏–∫–∞–º–∏.*',
            r'—Å\s+—Ö–æ—Ä–æ—à–∏–º\s+–ø—Ä–æ–∏–∑–Ω–æ—à–µ–Ω–∏–µ–º.*',
            # –°–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏—è
            r'(\b—Ñ—Ä–∞–≥–º–µ–Ω—Ç\w*\s*){3,}',  # –ü–æ–≤—Ç–æ—Ä–µ–Ω–∏–µ —Å–ª–æ–≤–∞ "—Ñ—Ä–∞–≥–º–µ–Ω—Ç"
            r'(\b—Ä–∞–∑–≥–æ–≤–æ—Ä\w*\s*){3,}',  # –ü–æ–≤—Ç–æ—Ä–µ–Ω–∏–µ —Å–ª–æ–≤–∞ "—Ä–∞–∑–≥–æ–≤–æ—Ä"
            # –û–±—â–∏–µ –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏—è (–±–æ–ª–µ–µ —Å—Ç—Ä–æ–≥–∏–µ)
            r'\b(\w+)\s+\1(\s+\1){2,}',  # –°–ª–æ–≤–æ –ø–æ–≤—Ç–æ—Ä–µ–Ω–Ω–æ–µ 3+ —Ä–∞–∑–∞ –ø–æ–¥—Ä—è–¥
        ]
        
        import re
        
        original_text = text
        
        # –ü—Ä–∏–º–µ–Ω—è–µ–º —Ñ–∏–ª—å—Ç—Ä—ã
        for pattern in hallucination_patterns:
            text = re.sub(pattern, '', text, flags=re.IGNORECASE)
        
        # –û—á–∏—â–∞–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã –∏ –∑–Ω–∞–∫–∏ –ø—Ä–µ–ø–∏–Ω–∞–Ω–∏—è
        text = re.sub(r'\s+', ' ', text).strip()
        text = re.sub(r'^[,.\s-]+|[,.\s-]+$', '', text)
        
        # –ï—Å–ª–∏ –≤–µ—Å—å —Ç–µ–∫—Å—Ç –±—ã–ª —É–¥–∞–ª–µ–Ω –∫–∞–∫ –≥–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏—è, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –ø—É—Å—Ç—É—é —Å—Ç—Ä–æ–∫—É
        if not text:
            logger.debug(f"–¢–µ–∫—Å—Ç —É–¥–∞–ª–µ–Ω –∫–∞–∫ –≥–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏—è: '{original_text}'")
            return ""
        
        # –õ–æ–≥–∏—Ä—É–µ–º, –µ—Å–ª–∏ —Ç–µ–∫—Å—Ç –±—ã–ª –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ –∏–∑–º–µ–Ω–µ–Ω
        if len(text) < len(original_text) * 0.7:
            logger.debug(f"–ì–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏—è –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–∞: '{original_text}' ‚Üí '{text}'")
        
        return text

    @log_function_call
    def transcribe_audio_segment(self, audio_path: str, start_time: float, 
                               end_time: float) -> Optional[str]:
        """
        –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä–æ–≤–∞—Ç—å —Å–µ–≥–º–µ–Ω—Ç –∞—É–¥–∏–æ.
        
        Args:
            audio_path: –ü—É—Ç—å –∫ –∞—É–¥–∏–æ —Ñ–∞–π–ª—É
            start_time: –í—Ä–µ–º—è –Ω–∞—á–∞–ª–∞ —Å–µ–≥–º–µ–Ω—Ç–∞ –≤ —Å–µ–∫—É–Ω–¥–∞—Ö
            end_time: –í—Ä–µ–º—è –∫–æ–Ω—Ü–∞ —Å–µ–≥–º–µ–Ω—Ç–∞ –≤ —Å–µ–∫—É–Ω–¥–∞—Ö
            
        Returns:
            str: –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –∏–ª–∏ None –ø—Ä–∏ –æ—à–∏–±–∫–µ
        """
        try:
            if not self.whisper_model:
                raise RuntimeError("–ú–æ–¥–µ–ª—å Whisper –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞")
            
            # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª –¥–ª—è —Å–µ–≥–º–µ–Ω—Ç–∞
            temp_file = self.file_manager.create_temp_file(suffix=".wav")
            
            try:
                # –ò–∑–≤–ª–µ–∫–∞–µ–º —Å–µ–≥–º–µ–Ω—Ç
                if not self.audio_processor.extract_audio_segment(
                    audio_path, temp_file, start_time, end_time - start_time):
                    logger.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å —Å–µ–≥–º–µ–Ω—Ç {start_time}-{end_time}")
                    return None
                
                # –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä—É–µ–º —Å–µ–≥–º–µ–Ω—Ç —Å –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ (–±–µ–∑ –≥–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏–π)
                result = self.whisper_model.transcribe(
                    temp_file,
                    language='ru',  # –†—É—Å—Å–∫–∏–π —è–∑—ã–∫ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
                    task='transcribe',
                    # –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –ø—Ä–æ—Ç–∏–≤ –≥–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏–π
                    temperature=0.0,  # –î–µ—Ç–µ—Ä–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
                    beam_size=1,      # –ü—Ä–æ—Å—Ç–æ–π greedy search - –º–µ–Ω–µ–µ —Å–∫–ª–æ–Ω–µ–Ω –∫ –≥–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏—è–º
                    best_of=1,        # –¢–æ–ª—å–∫–æ –æ–¥–∏–Ω –≤–∞—Ä–∏–∞–Ω—Ç - –±—ã—Å—Ç—Ä–µ–µ –∏ —Ç–æ—á–Ω–µ–µ
                    # –ù–ï –∏—Å–ø–æ–ª—å–∑—É–µ–º initial_prompt - –æ–Ω –≤—ã–∑—ã–≤–∞–µ—Ç –≥–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏–∏!
                    condition_on_previous_text=False,  # –ù–µ–∑–∞–≤–∏—Å–∏–º–∞—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è —Å–µ–≥–º–µ–Ω—Ç–æ–≤
                    fp16=False,  # –ü–æ–ª–Ω–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å
                    compression_ratio_threshold=2.4,  # –§–∏–ª—å—Ç—Ä –ø–ª–æ—Ö–æ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞
                    logprob_threshold=-1.0,  # –§–∏–ª—å—Ç—Ä –ø–æ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏
                    no_speech_threshold=0.6,  # –§–∏–ª—å—Ç—Ä —Ç–∏—à–∏–Ω—ã
                    # –ü–æ–¥–∞–≤–ª—è–µ–º –ø–æ–≤—Ç–æ—Ä—è—é—â–∏–µ—Å—è —Ç–æ–∫–µ–Ω—ã
                    suppress_tokens=[50256, 50257, 50258, 50259, 50260, 50261, 50262, 50263, 50264, 50265]
                )
                
                text = result.get('text', '').strip()
                
                # –§–∏–ª—å—Ç—Ä—É–µ–º –≥–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏–∏
                text = self._filter_hallucinations(text)
                
                if text:
                    logger.debug(f"–¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä–æ–≤–∞–Ω —Å–µ–≥–º–µ–Ω—Ç {start_time:.2f}-{end_time:.2f}s: '{text[:50]}...'")
                else:
                    logger.debug(f"–ü—É—Å—Ç–∞—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è –¥–ª—è —Å–µ–≥–º–µ–Ω—Ç–∞ {start_time:.2f}-{end_time:.2f}s")
                
                return text
            
            finally:
                # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
                self.file_manager.delete_file(temp_file)
        
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏ —Å–µ–≥–º–µ–Ω—Ç–∞ {start_time}-{end_time}: {str(e)}")
            return None
    
    @log_function_call
    def transcribe_full_audio(self, audio_path: str) -> Optional[str]:
        """
        –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä–æ–≤–∞—Ç—å –ø–æ–ª–Ω—ã–π –∞—É–¥–∏–æ —Ñ–∞–π–ª –±–µ–∑ –¥–∏–∞—Ä–∏–∑–∞—Ü–∏–∏.
        
        Args:
            audio_path: –ü—É—Ç—å –∫ –∞—É–¥–∏–æ —Ñ–∞–π–ª—É
            
        Returns:
            str: –ü–æ–ª–Ω—ã–π —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
        """
        try:
            if not self.whisper_model:
                raise RuntimeError("–ú–æ–¥–µ–ª—å Whisper –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞")
            
            logger.info(f"–¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è –ø–æ–ª–Ω–æ–≥–æ —Ñ–∞–π–ª–∞: {audio_path}")
            
            result = self.whisper_model.transcribe(
                audio_path,
                language='ru',
                task='transcribe',
                verbose=False,
                # –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –ø–æ–ª–Ω–æ–≥–æ —Ñ–∞–π–ª–∞ (–±–µ–∑ –≥–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏–π)
                temperature=0.0,  # –î–µ—Ç–µ—Ä–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
                beam_size=1,      # –ü—Ä–æ—Å—Ç–æ–π greedy search
                best_of=1,        # –û–¥–∏–Ω –≤–∞—Ä–∏–∞–Ω—Ç - –±–µ–∑ –ø–µ—Ä–µ–±–æ—Ä–∫–∏
                # –ù–ï –∏—Å–ø–æ–ª—å–∑—É–µ–º initial_prompt - –æ–Ω —Å–æ–∑–¥–∞–µ—Ç –≥–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏–∏!
                condition_on_previous_text=True,  # –ö–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è –¥–ª–∏–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞ OK
                fp16=False,       # –ü–æ–ª–Ω–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å
                compression_ratio_threshold=2.4,
                logprob_threshold=-1.0,
                no_speech_threshold=0.6,
                # –ü–æ–¥–∞–≤–ª—è–µ–º —Ç–æ–∫–µ–Ω—ã, —Å–∫–ª–æ–Ω–Ω—ã–µ –∫ –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏—è–º
                suppress_tokens=[50256, 50257, 50258, 50259, 50260, 50261, 50262, 50263, 50264, 50265]
            )
            
            text = result.get('text', '').strip()
            
            # –§–∏–ª—å—Ç—Ä—É–µ–º –≥–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏–∏
            text = self._filter_hallucinations(text)
            
            logger.info(f"–ü–æ–ª–Ω–∞—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞, –¥–ª–∏–Ω–∞ —Ç–µ–∫—Å—Ç–∞: {len(text)} —Å–∏–º–≤–æ–ª–æ–≤")
            
            return text
        
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª–Ω–æ–π —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏ {audio_path}: {str(e)}")
            return None
    
    def _merge_short_segments(self, segments: List[SpeakerSegment], 
                             min_duration: float = 3.0) -> List[SpeakerSegment]:
        """
        –û–±—ä–µ–¥–∏–Ω–∏—Ç—å –∫–æ—Ä–æ—Ç–∫–∏–µ —Å–µ–≥–º–µ–Ω—Ç—ã –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏.
        
        Args:
            segments: –°–ø–∏—Å–æ–∫ —Å–µ–≥–º–µ–Ω—Ç–æ–≤ —Å–ø–∏–∫–µ—Ä–æ–≤
            min_duration: –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Å–µ–≥–º–µ–Ω—Ç–∞ –≤ —Å–µ–∫—É–Ω–¥–∞—Ö
            
        Returns:
            List[SpeakerSegment]: –û–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–µ —Å–µ–≥–º–µ–Ω—Ç—ã
        """
        if not segments:
            return segments
        
        merged_segments = []
        current_segment = None
        
        for segment in segments:
            if current_segment is None:
                # –ü–µ—Ä–≤—ã–π —Å–µ–≥–º–µ–Ω—Ç
                current_segment = SpeakerSegment(
                    speaker_id=segment.speaker_id,
                    start_time=segment.start_time,
                    end_time=segment.end_time,
                    text=""
                )
            elif (segment.speaker_id == current_segment.speaker_id and 
                  segment.start_time - current_segment.end_time < 1.0):  # –ü–∞—É–∑–∞ –º–µ–Ω—å—à–µ 1 —Å–µ–∫
                # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Å —Ç–µ–∫—É—â–∏–º —Å–µ–≥–º–µ–Ω—Ç–æ–º —Ç–æ–≥–æ –∂–µ —Å–ø–∏–∫–µ—Ä–∞
                current_segment.end_time = segment.end_time
            else:
                # –ó–∞–≤–µ—Ä—à–∞–µ–º —Ç–µ–∫—É—â–∏–π —Å–µ–≥–º–µ–Ω—Ç
                if current_segment.duration >= min_duration:
                    merged_segments.append(current_segment)
                else:
                    # –ö–æ—Ä–æ—Ç–∫–∏–π —Å–µ–≥–º–µ–Ω—Ç - –ø—ã—Ç–∞–µ–º—Å—è –ø—Ä–∏—Å–æ–µ–¥–∏–Ω–∏—Ç—å –∫ –ø—Ä–µ–¥—ã–¥—É—â–µ–º—É
                    if merged_segments and merged_segments[-1].speaker_id == current_segment.speaker_id:
                        merged_segments[-1].end_time = current_segment.end_time
                    else:
                        merged_segments.append(current_segment)
                
                # –ù–∞—á–∏–Ω–∞–µ–º –Ω–æ–≤—ã–π —Å–µ–≥–º–µ–Ω—Ç
                current_segment = SpeakerSegment(
                    speaker_id=segment.speaker_id,
                    start_time=segment.start_time,
                    end_time=segment.end_time,
                    text=""
                )
        
        # –î–æ–±–∞–≤–ª—è–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π —Å–µ–≥–º–µ–Ω—Ç
        if current_segment:
            if current_segment.duration >= min_duration:
                merged_segments.append(current_segment)
            elif merged_segments and merged_segments[-1].speaker_id == current_segment.speaker_id:
                merged_segments[-1].end_time = current_segment.end_time
            else:
                merged_segments.append(current_segment)
        
        original_count = len(segments)
        merged_count = len(merged_segments)
        logger.info(f"–û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Å–µ–≥–º–µ–Ω—Ç–æ–≤: {original_count} ‚Üí {merged_count} "
                   f"(—Å–æ–∫—Ä–∞—â–µ–Ω–æ –Ω–∞ {original_count - merged_count})")
        
        return merged_segments

    @log_function_call
    def transcribe_with_speakers(self, job: ProcessingJob, audio_path: str, 
                               segments: List[SpeakerSegment]) -> bool:
        """
        –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä–æ–≤–∞—Ç—å –∞—É–¥–∏–æ —Å –ø—Ä–∏–≤—è–∑–∫–æ–π –∫ —Å–ø–∏–∫–µ—Ä–∞–º.
        
        Args:
            job: –ó–∞–¥–∞—á–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏
            audio_path: –ü—É—Ç—å –∫ –∞—É–¥–∏–æ —Ñ–∞–π–ª—É
            segments: –°–µ–≥–º–µ–Ω—Ç—ã —Å–ø–∏–∫–µ—Ä–æ–≤
            
        Returns:
            bool: True –µ—Å–ª–∏ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è —É—Å–ø–µ—à–Ω–∞
        """
        try:
            job.update_progress(ProcessingStatus.TRANSCRIBING, "–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Å–µ–≥–º–µ–Ω—Ç–æ–≤", 65.0)
            
            if not segments:
                logger.warning("–ù–µ—Ç —Å–µ–≥–º–µ–Ω—Ç–æ–≤ –¥–ª—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏")
                return False
            
            # –û–±—ä–µ–¥–∏–Ω—è–µ–º –∫–æ—Ä–æ—Ç–∫–∏–µ —Å–µ–≥–º–µ–Ω—Ç—ã –¥–ª—è –ª—É—á—à–µ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
            original_count = len(segments)
            segments = self._merge_short_segments(segments, min_duration=2.0)
            
            if len(segments) != original_count:
                logger.info(f"–°–µ–≥–º–µ–Ω—Ç—ã –æ–±—ä–µ–¥–∏–Ω–µ–Ω—ã –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –∫–∞—á–µ—Å—Ç–≤–∞: {original_count} ‚Üí {len(segments)}")
            
            job.update_progress(ProcessingStatus.TRANSCRIBING, "–¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è —Å–µ–≥–º–µ–Ω—Ç–æ–≤", 70.0)
            total_segments = len(segments)
            transcribed_segments = []
            
            # –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä—É–µ–º –∫–∞–∂–¥—ã–π —Å–µ–≥–º–µ–Ω—Ç
            for i, segment in enumerate(segments):
                log_progress(i + 1, total_segments, "–¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è —Å–µ–≥–º–µ–Ω—Ç–æ–≤")
                
                # –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä—É–µ–º —Å–µ–≥–º–µ–Ω—Ç —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º –¥–ª—è –ª—É—á—à–µ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞
                if segment.duration > 1.0:  # –î–ª—è –¥–ª–∏–Ω–Ω—ã—Ö —Å–µ–≥–º–µ–Ω—Ç–æ–≤ –∏—Å–ø–æ–ª—å–∑—É–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç
                    text = self.transcribe_audio_segment_with_context(
                        audio_path, 
                        segment.start_time, 
                        segment.end_time,
                        context_before=2.0,  # 2 —Å–µ–∫—É–Ω–¥—ã –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –¥–æ
                        context_after=1.0    # 1 —Å–µ–∫—É–Ω–¥–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –ø–æ—Å–ª–µ
                    )
                else:
                    # –î–ª—è –∫–æ—Ä–æ—Ç–∫–∏—Ö —Å–µ–≥–º–µ–Ω—Ç–æ–≤ –æ–±—ã—á–Ω–∞—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è
                    text = self.transcribe_audio_segment(
                        audio_path, 
                        segment.start_time, 
                        segment.end_time
                    )
                
                if text:
                    # –û–±–Ω–æ–≤–ª—è–µ–º —Å–µ–≥–º–µ–Ω—Ç —Å —Ç–µ–∫—Å—Ç–æ–º
                    segment.text = text
                    transcribed_segments.append(segment)
                    logger.debug(f"–°–µ–≥–º–µ–Ω—Ç {segment.speaker_id} —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä–æ–≤–∞–Ω: '{text[:50]}...'")
                else:
                    logger.warning(f"–ü—É—Å—Ç–∞—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è –¥–ª—è —Å–µ–≥–º–µ–Ω—Ç–∞ {segment.speaker_id}")
                
                # –û–±–Ω–æ–≤–ª—è–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å
                progress = 70.0 + (i + 1) / total_segments * 20.0
                job.update_progress(ProcessingStatus.TRANSCRIBING, 
                                  f"–¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è {i+1}/{total_segments}", progress)
            
            # –û–±–Ω–æ–≤–ª—è–µ–º —Å–µ–≥–º–µ–Ω—Ç—ã –≤ –∑–∞–¥–∞—á–µ
            job.speaker_segments = transcribed_segments
            
            successful_count = len([s for s in transcribed_segments if s.text.strip()])
            logger.info(f"–¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞: {successful_count}/{total_segments} "
                       f"—Å–µ–≥–º–µ–Ω—Ç–æ–≤ —Å —Ç–µ–∫—Å—Ç–æ–º")
            
            return successful_count > 0
        
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏ —Å —Å–ø–∏–∫–µ—Ä–∞–º–∏: {str(e)}")
            return False
    
    @log_function_call
    def format_transcription_result(self, segments: List[SpeakerSegment]) -> str:
        """
        –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏.
        
        Args:
            segments: –°–µ–≥–º–µ–Ω—Ç—ã —Å —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä–æ–≤–∞–Ω–Ω—ã–º —Ç–µ–∫—Å—Ç–æ–º
            
        Returns:
            str: –û—Ç—Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
        """
        if not segments:
            return "–¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç —Ç–µ–∫—Å—Ç–∞."
        
        lines = []
        lines.append("# –†–µ–∑—É–ª—å—Ç–∞—Ç —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏")
        lines.append(f"# –°–æ–∑–¥–∞–Ω–æ: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        lines.append(f"# –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–µ–≥–º–µ–Ω—Ç–æ–≤: {len(segments)}")
        
        unique_speakers = len(set(s.speaker_id for s in segments if s.text.strip()))
        lines.append(f"# –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ø–∏–∫–µ—Ä–æ–≤: {unique_speakers}")
        lines.append("")
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Å–µ–≥–º–µ–Ω—Ç—ã
        for segment in segments:
            if not segment.text.strip():
                continue
            
            # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –≤—Ä–µ–º—è
            time_str = segment.formatted_time
            
            # –î–æ–±–∞–≤–ª—è–µ–º —Å—Ç—Ä–æ–∫—É —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏
            line = f"{time_str} [{segment.speaker_id}] - {segment.text.strip()}"
            lines.append(line)
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –≤ –∫–æ–Ω–µ—Ü
        lines.append("")
        lines.append("# –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞")
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Å–ø–∏–∫–µ—Ä–∞–º
        speaker_stats = {}
        for segment in segments:
            if not segment.text.strip():
                continue
            
            if segment.speaker_id not in speaker_stats:
                speaker_stats[segment.speaker_id] = {
                    'segments': 0,
                    'total_duration': 0.0,
                    'word_count': 0
                }
            
            speaker_stats[segment.speaker_id]['segments'] += 1
            speaker_stats[segment.speaker_id]['total_duration'] += segment.duration
            speaker_stats[segment.speaker_id]['word_count'] += len(segment.text.split())
        
        for speaker_id, stats in speaker_stats.items():
            lines.append(f"# {speaker_id}: {stats['segments']} —Å–µ–≥–º–µ–Ω—Ç–æ–≤, "
                        f"{stats['total_duration']:.1f}—Å, {stats['word_count']} —Å–ª–æ–≤")
        
        result = "\n".join(lines)
        logger.info(f"–†–µ–∑—É–ª—å—Ç–∞—Ç –æ—Ç—Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω: {len(lines)} —Å—Ç—Ä–æ–∫")
        
        return result
    
    @log_function_call
    def save_transcription_result(self, job: ProcessingJob, formatted_text: str) -> str:
        """
        –°–æ—Ö—Ä–∞–Ω–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏ –≤ —Ñ–∞–π–ª.
        
        Args:
            job: –ó–∞–¥–∞—á–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏
            formatted_text: –û—Ç—Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
            
        Returns:
            str: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
        """
        try:
            # –°–æ–∑–¥–∞–µ–º –∏–º—è —Ñ–∞–π–ª–∞
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"transcription_{job.id}_{timestamp}.txt"
            file_path = self.results_folder / filename
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–∞–π–ª
            with open(file_path, 'w', encoding='utf-8') as f:
                f.write(formatted_text)
            
            file_size = self.file_manager.get_file_size(str(file_path))
            logger.info(f"–†–µ–∑—É–ª—å—Ç–∞—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {file_path} ({file_size} –±–∞–π—Ç)")
            
            return str(file_path)
        
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞: {str(e)}")
            raise
    
    @log_function_call
    def process_full_pipeline(self, job: ProcessingJob) -> Optional[str]:
        """
        –í—ã–ø–æ–ª–Ω–∏—Ç—å –ø–æ–ª–Ω—ã–π –ø–∞–π–ø–ª–∞–π–Ω –æ–±—Ä–∞–±–æ—Ç–∫–∏.
        
        Args:
            job: –ó–∞–¥–∞—á–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏
            
        Returns:
            str: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –∏–ª–∏ None –ø—Ä–∏ –æ—à–∏–±–∫–µ
        """
        temp_files = []
        
        try:
            log_processing_step("–ù–∞—á–∞–ª–æ –ø–æ–ª–Ω–æ–≥–æ –ø–∞–π–ø–ª–∞–π–Ω–∞", f"–ó–∞–¥–∞—á–∞ {job.id}")
            
            # –≠—Ç–∞–ø 1: –û–±—Ä–∞–±–æ—Ç–∫–∞ –∞—É–¥–∏–æ —Ñ–∞–π–ª–æ–≤
            combined_audio_path = self.audio_processor.process_uploaded_files(job)
            if not combined_audio_path:
                job.set_error("–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∞—É–¥–∏–æ —Ñ–∞–π–ª–æ–≤")
                return None
            
            job.combined_audio_path = combined_audio_path
            
            # –≠—Ç–∞–ø 2: –î–∏–∞—Ä–∏–∑–∞—Ü–∏—è —Å–ø–∏–∫–µ—Ä–æ–≤ (–µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω–∞)
            segments = []
            if self.speaker_diarizer:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ pipeline –¥–∏–∞—Ä–∏–∑–∞—Ü–∏–∏ –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ –≥–æ—Ç–æ–≤
                if hasattr(self.speaker_diarizer, 'pipeline') and self.speaker_diarizer.pipeline is not None:
                    logger.info("üé§ –î–∏–∞—Ä–∏–∑–∞—Ç–æ—Ä –≥–æ—Ç–æ–≤ - –∑–∞–ø—É—Å–∫ –¥–∏–∞—Ä–∏–∑–∞—Ü–∏–∏ —Å–ø–∏–∫–µ—Ä–æ–≤")
                    try:
                        segments = self.speaker_diarizer.process_audio_with_diarization(job, combined_audio_path)
                        if segments:
                            logger.info(f"‚úÖ –î–∏–∞—Ä–∏–∑–∞—Ü–∏—è —É—Å–ø–µ—à–Ω–∞: –Ω–∞–π–¥–µ–Ω–æ {len(segments)} —Å–µ–≥–º–µ–Ω—Ç–æ–≤")
                            # –≠—Ç–∞–ø 3: –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è —Å –ø—Ä–∏–≤—è–∑–∫–æ–π –∫ —Å–ø–∏–∫–µ—Ä–∞–º
                            if not self.transcribe_with_speakers(job, combined_audio_path, segments):
                                job.set_error("–û—à–∏–±–∫–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏")
                                return None
                        else:
                            logger.warning("–î–∏–∞—Ä–∏–∑–∞—Ü–∏—è –Ω–µ –æ–±–Ω–∞—Ä—É–∂–∏–ª–∞ —Å–ø–∏–∫–µ—Ä–æ–≤")
                    except Exception as e:
                        logger.warning(f"–û—à–∏–±–∫–∞ –¥–∏–∞—Ä–∏–∑–∞—Ü–∏–∏: {str(e)}")
                else:
                    logger.warning("‚ö†Ô∏è –î–∏–∞—Ä–∏–∑–∞—Ç–æ—Ä —Å–æ–∑–¥–∞–Ω, –Ω–æ pipeline –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω - –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –¥–∏–∞—Ä–∏–∑–∞—Ü–∏—é")
                    self.speaker_diarizer = None  # –û—Ç–∫–ª—é—á–∞–µ–º –Ω–µ—Ä–∞–±–æ—Ç–∞—é—â–∏–π –¥–∏–∞—Ä–∏–∑–∞—Ç–æ—Ä
            
            # –ï—Å–ª–∏ –¥–∏–∞—Ä–∏–∑–∞—Ü–∏—è –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞ –∏–ª–∏ –Ω–µ —É–¥–∞–ª–∞—Å—å, –≤—ã–ø–æ–ª–Ω—è–µ–º –ø—Ä–æ—Å—Ç—É—é —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—é
            if not segments:
                logger.info("–í—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è –ø—Ä–æ—Å—Ç–∞—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è –±–µ–∑ –¥–∏–∞—Ä–∏–∑–∞—Ü–∏–∏")
                job.update_progress(ProcessingStatus.TRANSCRIBING, "–¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è –±–µ–∑ –¥–∏–∞—Ä–∏–∑–∞—Ü–∏–∏", 70.0)
                full_text = self.transcribe_full_audio(combined_audio_path)
                
                if full_text:
                    # –°–æ–∑–¥–∞–µ–º –µ–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω—ã–π —Å–µ–≥–º–µ–Ω—Ç
                    segments = [SpeakerSegment(
                        speaker_id="SPEAKER_01",
                        start_time=0.0,
                        end_time=job.total_duration or 0.0,
                        text=full_text
                    )]
                    job.speaker_segments = segments
                    job.speaker_count = 1
                else:
                    job.set_error("–ù–µ —É–¥–∞–ª–æ—Å—å –≤—ã–ø–æ–ª–Ω–∏—Ç—å —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—é")
                    return None
            
            # –≠—Ç–∞–ø 4: –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
            job.update_progress(ProcessingStatus.TRANSCRIBING, "–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞", 95.0)
            
            formatted_text = self.format_transcription_result(job.speaker_segments)
            result_path = self.save_transcription_result(job, formatted_text)
            
            logger.info(f"–ü–æ–ª–Ω—ã–π –ø–∞–π–ø–ª–∞–π–Ω –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ –¥–ª—è –∑–∞–¥–∞—á–∏ {job.id}")
            return result_path
        
        except Exception as e:
            error_msg = f"–û—à–∏–±–∫–∞ –≤ –ø–æ–ª–Ω–æ–º –ø–∞–π–ø–ª–∞–π–Ω–µ: {str(e)}"
            logger.error(error_msg)
            job.set_error(error_msg)
            return None
        
        finally:
            # –û—á–∏—Å—Ç–∫–∞ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
            if temp_files:
                self.file_manager.cleanup_temp_files(temp_files)
    
    def cleanup(self):
        """–û—á–∏—Å—Ç–∫–∞ —Ä–µ—Å—É—Ä—Å–æ–≤."""
        logger.info("–û—á–∏—Å—Ç–∫–∞ —Ä–µ—Å—É—Ä—Å–æ–≤ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ç–æ—Ä–∞")
        
        # –û—á–∏—Å—Ç–∫–∞ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
        if hasattr(self, 'speaker_diarizer') and self.speaker_diarizer:
            self.speaker_diarizer.cleanup()
        
        # –û—á–∏—Å—Ç–∫–∞ –º–æ–¥–µ–ª–∏ Whisper
        if self.whisper_model:
            try:
                import torch
                if torch.cuda.is_available():
                    torch.cuda.empty_cache()
            except ImportError:
                pass
            self.whisper_model = None
        
        logger.info("–û—á–∏—Å—Ç–∫–∞ —Ä–µ—Å—É—Ä—Å–æ–≤ –∑–∞–≤–µ—Ä—à–µ–Ω–∞") 